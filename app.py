import streamlit as st
from PIL import Image
import torch
from transformers import ViTForImageClassification, AutoImageProcessor

# ---------------------------
# 0. Streamlit ì œëª©
# ---------------------------
st.title("ğŸ± ìŒì‹ ì´ë¯¸ì§€ ë¶„ë¥˜ê¸° (ViT-B16 HuggingFace)")

# âš ï¸ ë°ëª¨ ì•ˆë‚´ ë°°ë„ˆ
st.markdown(
    """
    <div style='padding:15px; background-color:#ffe6e6; border:2px solid #ff4d4d; border-radius:10px;'>
        <h3 style='color:#cc0000;'>âš ï¸ í˜„ì¬ëŠ” ë°ëª¨ ë²„ì „ì…ë‹ˆë‹¤.</h3>
        <p style='font-size:16px; color:#333;'>
        ì˜ì–‘ì •ë³´ ì¹´ë“œ ì¶œë ¥ì€ <b>baklava, beef tartare, cannoli, churros</b> 4ê°œ í´ë˜ìŠ¤ë§Œ ì§€ì›í•©ë‹ˆë‹¤.<br>
        50ê°œì˜ ìŒì‹ë¶„ë¥˜ê°€ ê°€ëŠ¥í•˜ì§€ë§Œ ì˜ì–‘ì •ë³´ ì¹´ë“œëŠ” í‘œì‹œë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
        </p>
    </div>
    """,
    unsafe_allow_html=True
)

# ---------------------------
# 1. í´ë˜ìŠ¤ ì´ë¦„ ë¶ˆëŸ¬ì˜¤ê¸°
# ---------------------------
with open("classes.txt", "r", encoding="utf-8") as f:
    classes = [line.strip() for line in f.readlines()]

# ---------------------------
# 2. ëª¨ë¸ + processor ì •ì˜
# ---------------------------
model = ViTForImageClassification.from_pretrained(
    "google/vit-base-patch16-224",
    num_labels=len(classes),
    ignore_mismatched_sizes=True
)
state_dict = torch.load("vit_best.pth", map_location="cpu")
model.load_state_dict(state_dict)
model.eval()

processor = AutoImageProcessor.from_pretrained("google/vit-base-patch16-224")

# ---------------------------
# 3. ì˜ì–‘ ì •ë³´ ì¹´ë“œ (JSON - ë°ëª¨ìš©)
# ---------------------------
food_info = {
    "baklava": {
        "ì¹¼ë¡œë¦¬": "430 kcal (100g)",
        "íƒ„ìˆ˜í™”ë¬¼": "55 g",
        "ë‹¨ë°±ì§ˆ": "6 g",
        "ì§€ë°©": "22 g",
        "ì„¤ëª…": "í•„ë¡œ ë°˜ì£½ê³¼ ê²¬ê³¼ë¥˜, ê¿€ì„ ì¸µì¸µì´ ìŒ“ì•„ ë§Œë“  ì§€ì¤‘í•´ ì§€ì—­ì˜ ë‹¬ì½¤í•œ ë””ì €íŠ¸"
    },
    "beef tartare": {
        "ì¹¼ë¡œë¦¬": "250 kcal (100g)",
        "íƒ„ìˆ˜í™”ë¬¼": "0 g",
        "ë‹¨ë°±ì§ˆ": "26 g",
        "ì§€ë°©": "16 g",
        "ì„¤ëª…": "ì‹ ì„ í•œ ìƒê³ ê¸°ë¥¼ ë‹¤ì ¸ ì–‘ë…ê³¼ í•¨ê»˜ ìƒìœ¼ë¡œ ë¨¹ëŠ” ìš”ë¦¬, ë‹¬ê±€ ë…¸ë¥¸ìì™€ ê³ë“¤ì—¬ ì œê³µ"
    },
    "cannoli": {
        "ì¹¼ë¡œë¦¬": "320 kcal (100g)",
        "íƒ„ìˆ˜í™”ë¬¼": "34 g",
        "ë‹¨ë°±ì§ˆ": "6 g",
        "ì§€ë°©": "18 g",
        "ì„¤ëª…": "ì‹œì¹ ë¦¬ì•„ ì „í†µ ë””ì €íŠ¸, íŠ€ê¸´ í˜ì´ìŠ¤íŠ¸ë¦¬ íŠœë¸Œì— ë‹¬ì½¤í•œ ë¦¬ì½”íƒ€ í¬ë¦¼ì„ ì±„ìš´ ê³¼ì"
    },
    "churros": {
        "ì¹¼ë¡œë¦¬": "410 kcal (100g)",
        "íƒ„ìˆ˜í™”ë¬¼": "46 g",
        "ë‹¨ë°±ì§ˆ": "5 g",
        "ì§€ë°©": "24 g",
        "ì„¤ëª…": "ë°€ê°€ë£¨ ë°˜ì£½ì„ íŠ€ê²¨ ì„¤íƒ•ì„ ë¿Œë¦° ìŠ¤í˜ì¸ ê°„ì‹, ì´ˆì½œë¦¿ ì†ŒìŠ¤ì™€ í•¨ê»˜ ì¦ê¹€"
    }
}

# ---------------------------
# 4. íŒŒì¼ ì—…ë¡œë“œ UI
# ---------------------------
uploaded_file = st.file_uploader("ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["jpg", "png", "jpeg"])

# ---------------------------
# 5. ì¶”ë¡ 
# ---------------------------
if uploaded_file is not None:
    img = Image.open(uploaded_file).convert("RGB")
    st.image(img, caption="ì—…ë¡œë“œëœ ì´ë¯¸ì§€", use_container_width=True)

    inputs = processor(images=img, return_tensors="pt")

    with torch.no_grad():
        outputs = model(**inputs).logits
        pred = outputs.argmax(1).item()

    result = classes[pred]
    st.success(f"ì˜ˆì¸¡ ê²°ê³¼: **{result}**")

    # ì˜ì–‘ì •ë³´ ì¹´ë“œ ì¶œë ¥
    if result in food_info:
        info = food_info[result]
        st.info(
            f"ì¹¼ë¡œë¦¬: {info['ì¹¼ë¡œë¦¬']}\n"
            f"íƒ„ìˆ˜í™”ë¬¼: {info['íƒ„ìˆ˜í™”ë¬¼']}\n"
            f"ë‹¨ë°±ì§ˆ: {info['ë‹¨ë°±ì§ˆ']}\n"
            f"ì§€ë°©: {info['ì§€ë°©']}\n\n"
            f"ì„¤ëª…: {info['ì„¤ëª…']}"
        )
    else:
        st.warning("âš ï¸ í•´ë‹¹ ìŒì‹ì˜ ì˜ì–‘ì •ë³´ëŠ” ì•„ì§ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
